{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF702 Redes Neurais\n",
    "Esse notebook contém um script base para o projeto da disciplina IF702 Redes Neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A leitura do data set é feita utilizando a biblioteca `pandas`. O presente exemplo importa a base de dados `mammography`, assim, caso você esteja trabalhando com outro data set, modifique esta linha.\n",
    "Para importar o conjunto de dados do PAKDD, use a função `pd.read_table` ao invés da `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('data/mammography.csv.zip')\n",
    "data_set.drop_duplicates(inplace=True)  # Remove exemplos repetidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o data set em atributos dependentes (X = features) e independentes (y = classe). No caso do `mammography` a classe majoritária está codificada como -1 e a classe minoritária está codificada como 1. Para treinar nossa rede neural precisamos que os valores de classe sejam 0 e 1, assim modificamos a codificação da majoritária para 0.\n",
    "\n",
    "Perceba que esse pré-processamento varia de data set para data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_set.iloc[:, :-1].values\n",
    "y = data_set.iloc[:, -1].values\n",
    "y = np.where(y == -1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui definimos a arquitetura de nossa rede neural e o processo de treinamento e teste da mesma.\n",
    "\n",
    "O treinamento é feito através de repetidas divisões do conjunto de dados em treinamento, validação e teste. O número de repetições e os tamanhos dos conjuntos de treino, validação, e teste podem ser facilmente modificados.\n",
    "\n",
    "Para testar o comportamento da rede com diferentes funções de sampling, as mesmas devem ser implementadas e aplicadas ao conjunto de treinamento antes da normalização dos dados (você também pode investigar qual o efeito de aplicar o sampling após a normalização).\n",
    "\n",
    "É importante lembrar de normalizar os dados. A classe `StandardScaler` centraliza as variáveis e transforma as features para terem variância unitária. Você pode testar outras opções como o `MinMaxScaler`.\n",
    "\n",
    "Todas as alternativas estão disponíveis em:\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing.\n",
    "\n",
    "A arquitetura da rede é então definida como tendo apenas uma camada escondida. O código é bem intuitivo e a adição de novas camadas pode ser feita através da função `add`.\n",
    "\n",
    "Várias funções de otimização estão disponíveis e seus parâmetros também podem ser definidos. \n",
    "\n",
    "Confira os exemplos em: https://keras.io/optimizers/\n",
    "\n",
    "Um maior controle sobre quando a rede deve parar de treinar também pode ser exercido. \n",
    "\n",
    "Confira a documentação da classe `EarlyStopping`: https://keras.io/callbacks/\n",
    "\n",
    "Por fim, predições são feitas para o conjunto de teste e métricas de desempenho são calculadas.\n",
    "\n",
    "Mais métricas de desempenho: http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "\n",
    "for _ in range(10):\n",
    "    ## Treino: 60%, Validação: 20%, Teste: 20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "    \n",
    "    ## Aplicar a funcao de sampling ao conjunto de treinamento\n",
    "    # TO DO\n",
    "    \n",
    "    ## Normalizar as features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    ## Treinar a rede\n",
    "    # Cria o esboço da rede.\n",
    "    classifier = Sequential()\n",
    "    # Adiciona a primeira camada escondida contendo 16 neurônios e função de ativação tangente \n",
    "    # hiperbólica. Por ser a primeira camada adicionada à rede, precisamos especificar a \n",
    "    # dimensão de entrada (número de features do data set), no caso do mammography são 6.\n",
    "    classifier.add(Dense(16, activation='tanh', input_dim=6))\n",
    "    # Adiciona a camada de saída. Como nosso problema é binário, só precisamos de 1 neurônio \n",
    "    # e função de ativação sigmoidal. A partir da segunda camada adicionada, keras já consegue \n",
    "    # inferir o número de neurônios de entrada (nesse caso 16) e nós não precisamos mais \n",
    "    # especificar.\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "    # Compila o modelo especificando o otimizador, a função de custo, e opcionalmente métricas \n",
    "    # para serem observadas durante o treinamento.\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    # Treina a rede, especificando o tamanho do batch, o número máximo de épocas, se deseja \n",
    "    # parar prematuramente caso o erro de validação não decresça, e o conjunto de validação.\n",
    "    classifier.fit(X_train, y_train, batch_size=32, epochs=10000, \n",
    "                   callbacks=[EarlyStopping()], validation_data=(X_val, y_val))\n",
    "    \n",
    "    ## Fazer predições no conjunto de teste\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_class = classifier.predict_classes(X_test)\n",
    "    ## Computar métricas de desempenho\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_class))\n",
    "    recalls.append(recall_score(y_test, y_pred_class))\n",
    "    precisions.append(precision_score(y_test, y_pred_class))\n",
    "    f1s.append(f1_score(y_test, y_pred_class))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "accuracies_mean, accuracies_std = np.mean(accuracies), np.std(accuracies)\n",
    "recalls_mean, recalls_std = np.mean(recalls), np.std(recalls)\n",
    "precisions_mean, precisions_std = np.mean(precisions), np.std(precisions)\n",
    "f1s_mean, f1s_std = np.mean(f1s), np.std(f1s)\n",
    "aucs_mean, aucs_std = np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\tmean\\t\\t\\tstd')\n",
    "print('Accuracy\\t', accuracies_mean, '\\t', accuracies_std)\n",
    "print('Recall\\t\\t', recalls_mean, '\\t', recalls_std)\n",
    "print('Precision\\t', precisions_mean, '\\t', precisions_std)\n",
    "print('F1\\t\\t', f1s_mean, '\\t', f1s_std)\n",
    "print('AUC\\t\\t', aucs_mean, '\\t', aucs_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
