{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF702 Redes Neurais\n",
    "Esse notebook contém um script base para o projeto da disciplina IF702 Redes Neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A leitura do data set é feita utilizando `pandas`. O presente exemplo importa a base de dados `mammography`, assim, caso você esteja trabalhando com outro data set modifique esta linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('data/mammography.csv')\n",
    "data_set.drop_duplicates(inplace=True)  # Remove exemplos repetidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o data set em atributos dependentes (X = features) e independentes (y = classe). No caso do `mammography` a classe majoritária está codificada como -1 e a classe minoritária está codificada como 1. Para treinar nossa rede neural precisamos que os valores de classe sejam 0 e 1, assim modificamos a codificação da majoritária para 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_set.iloc[:, :-1].values\n",
    "y = data_set.iloc[:, -1].values\n",
    "y = np.where(y == -1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui definimos a arquitetura de nossa rede neural e o processo de treinamento e teste da mesma.\n",
    "\n",
    "O treinamento é feito através de repetidas divisões do conjunto de dados em treinamento, validação e teste. O número de repetições e os tamanhos dos conjuntos de treino, validação, e teste podem ser facilmente modificados.\n",
    "\n",
    "Para testar o comportamento da rede com diferentes funções de sampling, as mesmas devem ser implementadas e aplicadas ao conjunto de treinamento antes da normalização dos dados (você também pode investigar qual o efeito de aplicar o sampling após a normalização).\n",
    "\n",
    "É importante lembrar de normalizar os dados. A classe `StandardScaler` centraliza as variáveis e transforma as features para terem variância unitária. Você pode testar outras opções como o `MinMaxScaler`.\n",
    "\n",
    "Todas as alternativas estão disponíveis em:\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing.\n",
    "\n",
    "A arquitetura da rede é então definida como tendo apenas uma camada escondida. O código é bem intuitivo e a adição de novas camadas pode ser feita através da função `add`.\n",
    "\n",
    "Várias funções de otimização estão disponíveis e seus parâmetros também podem ser definidos. \n",
    "\n",
    "Confira os exemplos em: https://keras.io/optimizers/\n",
    "\n",
    "Um maior controle sobre quando a rede deve parar de treinar também pode ser exercido. \n",
    "\n",
    "Confira a documentação da classe `EarlyStopping`: https://keras.io/callbacks/\n",
    "\n",
    "Por fim, predições são feitas para o conjunto de teste e métricas de desempenho são calculadas.\n",
    "\n",
    "Mais métricas de desempenho: http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5681 - acc: 0.7721 - val_loss: 0.3773 - val_acc: 0.9650\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2776 - acc: 0.9726 - val_loss: 0.1998 - val_acc: 0.9707\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1587 - acc: 0.9747 - val_loss: 0.1310 - val_acc: 0.9720\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1123 - acc: 0.9766 - val_loss: 0.1045 - val_acc: 0.9739\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0928 - acc: 0.9781 - val_loss: 0.0926 - val_acc: 0.9752\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0834 - acc: 0.9796 - val_loss: 0.0866 - val_acc: 0.9745\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0781 - acc: 0.9803 - val_loss: 0.0830 - val_acc: 0.9726\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0749 - acc: 0.9805 - val_loss: 0.0803 - val_acc: 0.9726\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0727 - acc: 0.9811 - val_loss: 0.0792 - val_acc: 0.9726\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0711 - acc: 0.9809 - val_loss: 0.0777 - val_acc: 0.9739\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0699 - acc: 0.9809 - val_loss: 0.0769 - val_acc: 0.9726\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0689 - acc: 0.9807 - val_loss: 0.0767 - val_acc: 0.9739\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0680 - acc: 0.9803 - val_loss: 0.0757 - val_acc: 0.9732\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0671 - acc: 0.9809 - val_loss: 0.0757 - val_acc: 0.9732\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.6014 - acc: 0.7522 - val_loss: 0.4220 - val_acc: 0.9439\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.3066 - acc: 0.9580 - val_loss: 0.2096 - val_acc: 0.9739\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1650 - acc: 0.9741 - val_loss: 0.1271 - val_acc: 0.9796\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1134 - acc: 0.9754 - val_loss: 0.0968 - val_acc: 0.9822\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0936 - acc: 0.9771 - val_loss: 0.0837 - val_acc: 0.9828\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0848 - acc: 0.9773 - val_loss: 0.0774 - val_acc: 0.9803\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0800 - acc: 0.9773 - val_loss: 0.0735 - val_acc: 0.9796\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0769 - acc: 0.9775 - val_loss: 0.0709 - val_acc: 0.9803\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0749 - acc: 0.9779 - val_loss: 0.0702 - val_acc: 0.9783\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0739 - acc: 0.9781 - val_loss: 0.0680 - val_acc: 0.9790\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0724 - acc: 0.9777 - val_loss: 0.0674 - val_acc: 0.9790\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0716 - acc: 0.9779 - val_loss: 0.0663 - val_acc: 0.9796\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0707 - acc: 0.9781 - val_loss: 0.0654 - val_acc: 0.9783\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0700 - acc: 0.9781 - val_loss: 0.0650 - val_acc: 0.9790\n",
      "Epoch 15/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0694 - acc: 0.9779 - val_loss: 0.0648 - val_acc: 0.9796\n",
      "Epoch 16/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0689 - acc: 0.9783 - val_loss: 0.0640 - val_acc: 0.9790\n",
      "Epoch 17/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0684 - acc: 0.9790 - val_loss: 0.0635 - val_acc: 0.9796\n",
      "Epoch 18/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0681 - acc: 0.9786 - val_loss: 0.0632 - val_acc: 0.9790\n",
      "Epoch 19/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0678 - acc: 0.9779 - val_loss: 0.0629 - val_acc: 0.9783\n",
      "Epoch 20/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0674 - acc: 0.9788 - val_loss: 0.0635 - val_acc: 0.9783\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5299 - acc: 0.8178 - val_loss: 0.3765 - val_acc: 0.9694\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2692 - acc: 0.9711 - val_loss: 0.1864 - val_acc: 0.9758\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1480 - acc: 0.9741 - val_loss: 0.1177 - val_acc: 0.9732\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1077 - acc: 0.9749 - val_loss: 0.0933 - val_acc: 0.9771\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0925 - acc: 0.9766 - val_loss: 0.0825 - val_acc: 0.9783\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0853 - acc: 0.9764 - val_loss: 0.0768 - val_acc: 0.9790\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0811 - acc: 0.9773 - val_loss: 0.0734 - val_acc: 0.9803\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0784 - acc: 0.9779 - val_loss: 0.0713 - val_acc: 0.9796\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0767 - acc: 0.9775 - val_loss: 0.0699 - val_acc: 0.9803\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0750 - acc: 0.9777 - val_loss: 0.0686 - val_acc: 0.9809\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0738 - acc: 0.9775 - val_loss: 0.0676 - val_acc: 0.9815\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0727 - acc: 0.9771 - val_loss: 0.0672 - val_acc: 0.9815\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0719 - acc: 0.9777 - val_loss: 0.0667 - val_acc: 0.9822\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0715 - acc: 0.9769 - val_loss: 0.0662 - val_acc: 0.9822\n",
      "Epoch 15/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0710 - acc: 0.9779 - val_loss: 0.0662 - val_acc: 0.9822\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5550 - acc: 0.8063 - val_loss: 0.3847 - val_acc: 0.9510\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2791 - acc: 0.9565 - val_loss: 0.1923 - val_acc: 0.9688\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1499 - acc: 0.9726 - val_loss: 0.1218 - val_acc: 0.9771\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1046 - acc: 0.9762 - val_loss: 0.0978 - val_acc: 0.9771\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0877 - acc: 0.9766 - val_loss: 0.0881 - val_acc: 0.9777\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0799 - acc: 0.9777 - val_loss: 0.0834 - val_acc: 0.9777\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0758 - acc: 0.9775 - val_loss: 0.0808 - val_acc: 0.9783\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0733 - acc: 0.9773 - val_loss: 0.0795 - val_acc: 0.9796\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0715 - acc: 0.9781 - val_loss: 0.0783 - val_acc: 0.9803\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0703 - acc: 0.9783 - val_loss: 0.0774 - val_acc: 0.9796\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0688 - acc: 0.9786 - val_loss: 0.0780 - val_acc: 0.9783\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4709/4709 [==============================] - 0s - loss: 0.5068 - acc: 0.8261 - val_loss: 0.3514 - val_acc: 0.9554\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2454 - acc: 0.9696 - val_loss: 0.1773 - val_acc: 0.9739\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1358 - acc: 0.9760 - val_loss: 0.1177 - val_acc: 0.9739\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0990 - acc: 0.9769 - val_loss: 0.0975 - val_acc: 0.9771\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0851 - acc: 0.9769 - val_loss: 0.0896 - val_acc: 0.9764\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0782 - acc: 0.9773 - val_loss: 0.0848 - val_acc: 0.9777\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0742 - acc: 0.9779 - val_loss: 0.0820 - val_acc: 0.9783\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0716 - acc: 0.9779 - val_loss: 0.0802 - val_acc: 0.9783\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0700 - acc: 0.9790 - val_loss: 0.0790 - val_acc: 0.9783\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0683 - acc: 0.9792 - val_loss: 0.0780 - val_acc: 0.9783\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0671 - acc: 0.9792 - val_loss: 0.0775 - val_acc: 0.9777\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0663 - acc: 0.9798 - val_loss: 0.0765 - val_acc: 0.9777\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0656 - acc: 0.9792 - val_loss: 0.0762 - val_acc: 0.9790\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0649 - acc: 0.9796 - val_loss: 0.0757 - val_acc: 0.9796\n",
      "Epoch 15/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0639 - acc: 0.9796 - val_loss: 0.0749 - val_acc: 0.9790\n",
      "Epoch 16/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0634 - acc: 0.9809 - val_loss: 0.0744 - val_acc: 0.9796\n",
      "Epoch 17/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0628 - acc: 0.9805 - val_loss: 0.0745 - val_acc: 0.9790\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5464 - acc: 0.8443 - val_loss: 0.4045 - val_acc: 0.9420\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2959 - acc: 0.9622 - val_loss: 0.1925 - val_acc: 0.9790\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1530 - acc: 0.9758 - val_loss: 0.1082 - val_acc: 0.9809\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1045 - acc: 0.9760 - val_loss: 0.0818 - val_acc: 0.9815\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0881 - acc: 0.9773 - val_loss: 0.0719 - val_acc: 0.9815\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0805 - acc: 0.9773 - val_loss: 0.0667 - val_acc: 0.9809\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0762 - acc: 0.9781 - val_loss: 0.0635 - val_acc: 0.9815\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0732 - acc: 0.9777 - val_loss: 0.0618 - val_acc: 0.9796\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0712 - acc: 0.9783 - val_loss: 0.0612 - val_acc: 0.9815\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0692 - acc: 0.9788 - val_loss: 0.0590 - val_acc: 0.9815\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0683 - acc: 0.9783 - val_loss: 0.0585 - val_acc: 0.9815\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0674 - acc: 0.9786 - val_loss: 0.0586 - val_acc: 0.9822\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5372 - acc: 0.7862 - val_loss: 0.3677 - val_acc: 0.9484\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2727 - acc: 0.9628 - val_loss: 0.1971 - val_acc: 0.9752\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1572 - acc: 0.9741 - val_loss: 0.1286 - val_acc: 0.9764\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1139 - acc: 0.9754 - val_loss: 0.1029 - val_acc: 0.9758\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0973 - acc: 0.9752 - val_loss: 0.0903 - val_acc: 0.9777\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0898 - acc: 0.9775 - val_loss: 0.0832 - val_acc: 0.9796\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0856 - acc: 0.9773 - val_loss: 0.0789 - val_acc: 0.9790\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0828 - acc: 0.9773 - val_loss: 0.0759 - val_acc: 0.9796\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0811 - acc: 0.9781 - val_loss: 0.0731 - val_acc: 0.9803\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0798 - acc: 0.9781 - val_loss: 0.0707 - val_acc: 0.9815\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0786 - acc: 0.9783 - val_loss: 0.0700 - val_acc: 0.9790\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0779 - acc: 0.9781 - val_loss: 0.0674 - val_acc: 0.9803\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0772 - acc: 0.9788 - val_loss: 0.0655 - val_acc: 0.9809\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0768 - acc: 0.9783 - val_loss: 0.0656 - val_acc: 0.9803\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5316 - acc: 0.7679 - val_loss: 0.3778 - val_acc: 0.9223\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2819 - acc: 0.9486 - val_loss: 0.1992 - val_acc: 0.9675\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1550 - acc: 0.9724 - val_loss: 0.1275 - val_acc: 0.9745\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1072 - acc: 0.9771 - val_loss: 0.1014 - val_acc: 0.9764\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0884 - acc: 0.9771 - val_loss: 0.0917 - val_acc: 0.9771\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0790 - acc: 0.9792 - val_loss: 0.0868 - val_acc: 0.9777\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0739 - acc: 0.9800 - val_loss: 0.0848 - val_acc: 0.9764\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0711 - acc: 0.9805 - val_loss: 0.0830 - val_acc: 0.9777\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0687 - acc: 0.9798 - val_loss: 0.0822 - val_acc: 0.9777\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0672 - acc: 0.9803 - val_loss: 0.0821 - val_acc: 0.9745\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0659 - acc: 0.9803 - val_loss: 0.0817 - val_acc: 0.9745\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0651 - acc: 0.9800 - val_loss: 0.0815 - val_acc: 0.9758\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0644 - acc: 0.9809 - val_loss: 0.0822 - val_acc: 0.9739\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.5311 - acc: 0.8382 - val_loss: 0.3641 - val_acc: 0.9631\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.2604 - acc: 0.9726 - val_loss: 0.1794 - val_acc: 0.9701\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1419 - acc: 0.9741 - val_loss: 0.1151 - val_acc: 0.9745\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1028 - acc: 0.9779 - val_loss: 0.0930 - val_acc: 0.9758\n",
      "Epoch 5/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4709/4709 [==============================] - 0s - loss: 0.0885 - acc: 0.9779 - val_loss: 0.0838 - val_acc: 0.9758\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0817 - acc: 0.9779 - val_loss: 0.0787 - val_acc: 0.9771\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0783 - acc: 0.9783 - val_loss: 0.0752 - val_acc: 0.9771\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0758 - acc: 0.9783 - val_loss: 0.0737 - val_acc: 0.9777\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0742 - acc: 0.9781 - val_loss: 0.0716 - val_acc: 0.9764\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0730 - acc: 0.9788 - val_loss: 0.0712 - val_acc: 0.9764\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0719 - acc: 0.9786 - val_loss: 0.0690 - val_acc: 0.9777\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0712 - acc: 0.9777 - val_loss: 0.0688 - val_acc: 0.9777\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0704 - acc: 0.9777 - val_loss: 0.0674 - val_acc: 0.9777\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0697 - acc: 0.9792 - val_loss: 0.0675 - val_acc: 0.9783\n",
      "  32/1570 [..............................] - ETA: 0sTrain on 4709 samples, validate on 1570 samples\n",
      "Epoch 1/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.6200 - acc: 0.6968 - val_loss: 0.4454 - val_acc: 0.8847\n",
      "Epoch 2/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.3356 - acc: 0.9359 - val_loss: 0.2230 - val_acc: 0.9707\n",
      "Epoch 3/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1726 - acc: 0.9737 - val_loss: 0.1260 - val_acc: 0.9790\n",
      "Epoch 4/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.1139 - acc: 0.9762 - val_loss: 0.0943 - val_acc: 0.9803\n",
      "Epoch 5/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0933 - acc: 0.9754 - val_loss: 0.0814 - val_acc: 0.9796\n",
      "Epoch 6/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0839 - acc: 0.9766 - val_loss: 0.0749 - val_acc: 0.9796\n",
      "Epoch 7/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0790 - acc: 0.9771 - val_loss: 0.0712 - val_acc: 0.9803\n",
      "Epoch 8/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0759 - acc: 0.9775 - val_loss: 0.0689 - val_acc: 0.9796\n",
      "Epoch 9/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0736 - acc: 0.9777 - val_loss: 0.0672 - val_acc: 0.9796\n",
      "Epoch 10/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0721 - acc: 0.9779 - val_loss: 0.0661 - val_acc: 0.9803\n",
      "Epoch 11/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0708 - acc: 0.9775 - val_loss: 0.0653 - val_acc: 0.9815\n",
      "Epoch 12/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0696 - acc: 0.9781 - val_loss: 0.0644 - val_acc: 0.9822\n",
      "Epoch 13/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0689 - acc: 0.9788 - val_loss: 0.0639 - val_acc: 0.9809\n",
      "Epoch 14/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0678 - acc: 0.9781 - val_loss: 0.0632 - val_acc: 0.9809\n",
      "Epoch 15/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0671 - acc: 0.9781 - val_loss: 0.0630 - val_acc: 0.9828\n",
      "Epoch 16/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0666 - acc: 0.9792 - val_loss: 0.0627 - val_acc: 0.9828\n",
      "Epoch 17/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0662 - acc: 0.9792 - val_loss: 0.0621 - val_acc: 0.9809\n",
      "Epoch 18/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0654 - acc: 0.9794 - val_loss: 0.0619 - val_acc: 0.9815\n",
      "Epoch 19/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0652 - acc: 0.9792 - val_loss: 0.0616 - val_acc: 0.9822\n",
      "Epoch 20/10000\n",
      "4709/4709 [==============================] - 0s - loss: 0.0646 - acc: 0.9790 - val_loss: 0.0616 - val_acc: 0.9822\n",
      " 864/1570 [===============>..............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "\n",
    "for _ in range(10):\n",
    "    ## Treino: 60%, Validação: 20%, Teste: 20%\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "    \n",
    "    ## Aplicar a funcao de sampling ao conjunto de treinamento\n",
    "    \n",
    "    ## Normalizar as features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    ## Treinar a rede\n",
    "    # Cria o esboço da rede.\n",
    "    classifier = Sequential()\n",
    "    # Adiciona a primeira camada escondida contendo 16 neurônios e função de ativação tangente \n",
    "    # hiperbólica. Por ser a primeira camada adicionada à rede, precisamos especificar a \n",
    "    # dimensão de entrada (número de features do data set), no caso do mammography são 6.\n",
    "    classifier.add(Dense(16, activation='tanh', input_dim=6))\n",
    "    # Adiciona a camada de saída. Como nosso problema é binário, só precisamos de 1 neurônio \n",
    "    # e função de ativação sigmoidal. A partir da segunda camada adicionada, keras já consegue \n",
    "    # inferir o número de neurônios de entrada (nesse caso 16) e nós não precisamos mais \n",
    "    # especificar.\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "    # Compila o modelo especificando o otimizador, a função de custo, e opcionalmente métricas \n",
    "    # para serem observadas durante o treinamento.\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # Treina a rede, especificando o tamanho do batch, o número de máximo de épocas, se deseja \n",
    "    # parar prematuramente caso o erro de validação não decresça, e o conjunto de validação.\n",
    "    classifier.fit(X_train, y_train, batch_size=32, epochs=10000, \n",
    "                   callbacks=[EarlyStopping()], validation_data=(X_val, y_val))\n",
    "    \n",
    "    ## Fazer predições no conjunto de teste\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_class = classifier.predict_classes(X_test)\n",
    "    ## Computar métricas de desempenho\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_class))\n",
    "    recalls.append(recall_score(y_test, y_pred_class))\n",
    "    precisions.append(precision_score(y_test, y_pred_class))\n",
    "    f1s.append(f1_score(y_test, y_pred_class))\n",
    "    aucs.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "accuracies_mean, accuracies_std = np.mean(accuracies), np.std(accuracies)\n",
    "recalls_mean, recalls_std = np.mean(recalls), np.std(recalls)\n",
    "precisions_mean, precisions_std = np.mean(precisions), np.std(precisions)\n",
    "f1s_mean, f1s_std = np.mean(f1s), np.std(f1s)\n",
    "aucs_mean, aucs_std = np.mean(aucs), np.std(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tmean\t\t\tstd\n",
      "Accuracy\t 0.980318471338 \t 0.00221469282175\n",
      "Recall\t\t 0.497269374515 \t 0.0702867251351\n",
      "Precision\t 0.825037947908 \t 0.0501063829444\n",
      "F1\t\t 0.616670769253 \t 0.0514483306761\n",
      "AUC\t\t 0.949683739159 \t 0.0161241997456\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\tmean\\t\\t\\tstd')\n",
    "print('Accuracy\\t', accuracies_mean, '\\t', accuracies_std)\n",
    "print('Recall\\t\\t', recalls_mean, '\\t', recalls_std)\n",
    "print('Precision\\t', precisions_mean, '\\t', precisions_std)\n",
    "print('F1\\t\\t', f1s_mean, '\\t', f1s_std)\n",
    "print('AUC\\t\\t', aucs_mean, '\\t', aucs_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
